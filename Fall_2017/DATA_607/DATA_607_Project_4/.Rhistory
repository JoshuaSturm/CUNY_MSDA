test.ham <- TermDocumentMatrix(test.ham)
test.spam <- TermDocumentMatrix(test.spam)
test.ham <- removeSparseTerms(test.ham, 0.95)
test.spam <- removeSparseTerms(test.spam, 0.95)
comb <- c(test.ham, test.spam)
tr <- 0.75*comb
ts <- comb - tr
container <- create_container(comb, trainSize = tr, testSize = ts, virgin = FALSE)
knitr::opts_chunk$set(echo = TRUE, warn = F, message = F)
options(stringsAsFactors = F)
library(tidyverse)
library(wordcloud2)
library(tm)
library(quanteda)
library(RTextTools)
# Set working directory, import files as a corpus, and then convert each to a document matrix
setwd("~/GitHub/CUNY_MSDA/Fall_2017/DATA_607/DATA_607_Project_4")
# train.spam.corpus <- VCorpus(DirSource(directory="train/spam"))
# train.ham.corpus <- TermDocumentMatrix(VCorpus(DirSource(directory="train/ham")))
# test.spam.corpus <- TermDocumentMatrix(Corpus(DirSource(directory="test/spam")))
# test.ham.corpus <- TermDocumentMatrix(Corpus(DirSource(directory="test/ham")))
# direc <- "train/ham/"
# train.ham <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
# direc <- "train/spam/"
# train.spam <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
direc <- "test/ham/"
test.ham <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
direc <- "test/spam/"
test.spam <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
test.ham <- test.ham %>%
tm_map(content_transformer(tolower)) %>%
tm_map(stripWhitespace) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(stemDocument)
test.spam <- test.spam %>%
tm_map(content_transformer(tolower)) %>%
tm_map(stripWhitespace) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(stemDocument)
# train.ham <- train.ham %>%
#     tm_map(content_transformer(tolower)) %>%
#     tm_map(stripWhitespace) %>%
#     tm_map(removePunctuation) %>%
#     tm_map(removeNumbers) %>%
#     tm_map(removeWords, stopwords("english")) %>%
#     tm_map(stemDocument)
#
# train.spam <- train.spam %>%
#     tm_map(content_transformer(tolower)) %>%
#     tm_map(stripWhitespace) %>%
#     tm_map(removePunctuation) %>%
#     tm_map(removeNumbers) %>%
#     tm_map(removeWords, stopwords("english")) %>%
#     tm_map(stemDocument)
# test.ham <- tm_map(test.ham, PlainTextDocument)
# test.spam <- tm_map(test.spam, PlainTextDocument)
comb <- c(test.ham, test.spam)
tr <- 0.75*comb
dim(comb)
dims(comb)
nrow(comb)
# test.ham <- tm_map(test.ham, PlainTextDocument)
# test.spam <- tm_map(test.spam, PlainTextDocument)
comb <- c(test.ham, test.spam)
tr <- comb[1:4393,]
# test.ham <- tm_map(test.ham, PlainTextDocument)
# test.spam <- tm_map(test.spam, PlainTextDocument)
comb <- c(test.ham, test.spam)
tr <- comb[1:4393, ]
tr <- comb[1:4393, ]
comb
comb <- TermDocumentMatrix(comb)
dim(comb)
tr <- comb[1:4393, ]
comb
comb <- comb %>%
tm_map(content_transformer(tolower)) %>%
tm_map(stripWhitespace) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(stemDocument)
# direc <- "train/ham/"
# train.ham <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
# direc <- "train/spam/"
# train.spam <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
direc <- "test/ham/"
test.ham <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
direc <- "test/spam/"
test.spam <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
meta(test.ham)
meta(test.spam)
meta(train.ham)
head(meta(test.ham))
print(meta(test.spam))
View(meta(test.ham))
comb <- c(test.ham, test.spam)
comb <- c(test.ham, test.spam, recursive=T)
comb <- TermDocumentMatrix(comb)
comb
tr <- comb[1:4393, ]
ts <- comb[4394:5857, ]
ts$type
ts$nrow
ts$dimnames$Terms
ts$dimnames$Docs
comb <- removeSparseTerms(comb, 0.95)
tr <- comb[1:4393, ]
comb
comb <- TermDocumentMatrix(comb)
knitr::opts_chunk$set(echo = TRUE, warn = F, message = F)
options(stringsAsFactors = F)
library(tidyverse)
library(wordcloud2)
library(tm)
library(quanteda)
library(RTextTools)
# Set working directory, import files as a corpus, and then convert each to a document matrix
setwd("~/GitHub/CUNY_MSDA/Fall_2017/DATA_607/DATA_607_Project_4")
# train.spam.corpus <- VCorpus(DirSource(directory="train/spam"))
# train.ham.corpus <- TermDocumentMatrix(VCorpus(DirSource(directory="train/ham")))
# test.spam.corpus <- TermDocumentMatrix(Corpus(DirSource(directory="test/spam")))
# test.ham.corpus <- TermDocumentMatrix(Corpus(DirSource(directory="test/ham")))
# direc <- "train/ham/"
# train.ham <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
# direc <- "train/spam/"
# train.spam <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
direc <- "test/ham/"
test.ham <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
direc <- "test/spam/"
test.spam <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
test.ham <- test.ham %>%
tm_map(content_transformer(tolower)) %>%
tm_map(stripWhitespace) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(stemDocument) %>%
removeSparseTerms(sparse = 0.95)
test.ham <- test.ham %>%
tm_map(content_transformer(tolower)) %>%
tm_map(stripWhitespace) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(stemDocument)
test.spam <- test.spam %>%
tm_map(content_transformer(tolower)) %>%
tm_map(stripWhitespace) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(stemDocument)
# train.ham <- train.ham %>%
#     tm_map(content_transformer(tolower)) %>%
#     tm_map(stripWhitespace) %>%
#     tm_map(removePunctuation) %>%
#     tm_map(removeNumbers) %>%
#     tm_map(removeWords, stopwords("english")) %>%
#     tm_map(stemDocument)
#
# train.spam <- train.spam %>%
#     tm_map(content_transformer(tolower)) %>%
#     tm_map(stripWhitespace) %>%
#     tm_map(removePunctuation) %>%
#     tm_map(removeNumbers) %>%
#     tm_map(removeWords, stopwords("english")) %>%
#     tm_map(stemDocument)
comb <- c(test.ham, test.spam, recursive=T)
comb <- TermDocumentMatrix(comb)
comb <- removeSparseTerms(0.95)
comb <- removeSparseTerms(sparse = 0.95)
comb <- removeSparseTerms(comb, sparse = 0.95)
tr <- comb[1:4393, ]
tr <- sample(comb)
comb
container <- create_container(comb, trainSize = 1:4393, testSize = 4394:5857, virgin = FALSE)
dim(comb)
container <- create_container(comb, trainSize = 1:248, testSize = 249:326, virgin = FALSE)
meta(comb)
comb$nrow
comb$dimnames
comb$dimnames$Ters
comb$dimnames$Terms
test.ham
dim(test.ham)
test.ham$`0001.1999-12-10.kaminski.ham.txt`
test.ham[[1]]
test.ham[[1]]$content
test.ham[[1]]$meta
knitr::opts_chunk$set(echo = TRUE, warn = F, message = F)
options(stringsAsFactors = F)
library(tidyverse)
library(wordcloud2)
library(tm)
library(quanteda)
library(RTextTools)
# Set working directory, import files as a corpus, and then convert each to a document matrix
setwd("~/GitHub/CUNY_MSDA/Fall_2017/DATA_607/DATA_607_Project_4")
# train.spam.corpus <- VCorpus(DirSource(directory="train/spam"))
# train.ham.corpus <- TermDocumentMatrix(VCorpus(DirSource(directory="train/ham")))
# test.spam.corpus <- TermDocumentMatrix(Corpus(DirSource(directory="test/spam")))
# test.ham.corpus <- TermDocumentMatrix(Corpus(DirSource(directory="test/ham")))
# direc <- "train/ham/"
# train.ham <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
# direc <- "train/spam/"
# train.spam <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
direc <- "test/ham/"
test.ham <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
meta(test.ham, tag = "type") <- "ham"
direc <- "test/spam/"
test.spam <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
meta(test.spam, tag = "type") <- "spam"
test.ham <- test.ham %>%
tm_map(content_transformer(tolower)) %>%
tm_map(stripWhitespace) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(stemDocument)
test.spam <- test.spam %>%
tm_map(content_transformer(tolower)) %>%
tm_map(stripWhitespace) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(stemDocument)
# train.ham <- train.ham %>%
#     tm_map(content_transformer(tolower)) %>%
#     tm_map(stripWhitespace) %>%
#     tm_map(removePunctuation) %>%
#     tm_map(removeNumbers) %>%
#     tm_map(removeWords, stopwords("english")) %>%
#     tm_map(stemDocument)
#
# train.spam <- train.spam %>%
#     tm_map(content_transformer(tolower)) %>%
#     tm_map(stripWhitespace) %>%
#     tm_map(removePunctuation) %>%
#     tm_map(removeNumbers) %>%
#     tm_map(removeWords, stopwords("english")) %>%
#     tm_map(stemDocument)
# test.ham <- tm_map(test.ham, PlainTextDocument)
# test.spam <- tm_map(test.spam, PlainTextDocument)
comb <- c(test.ham, test.spam, recursive=T)
comb <- TermDocumentMatrix(comb)
comb <- removeSparseTerms(comb, sparse = 0.95)
tr <- sample(comb)
# tr <- comb[1:4393, ]
# ts <- comb[4394:5857, ]
# test.ham <- TermDocumentMatrix(test.ham)
# test.spam <- TermDocumentMatrix(test.spam)
#
# test.ham <- removeSparseTerms(test.ham, 0.95)
# test.spam <- removeSparseTerms(test.spam, 0.95)
types <- unlist(meta(tr, "type")[,1])
types <- unlist(meta(tr, "type")[,1])
types <- unlist(meta(tr, "type")[,1])
knitr::opts_chunk$set(echo = TRUE, warn = F, message = F)
options(stringsAsFactors = F)
setwd("~/GitHub/CUNY_MSDA/Fall_2017/DATA_607/DATA_607_Project_4")
setwd("~/GitHub/CUNY_MSDA/Fall_2017/DATA_607/DATA_607_Project_4")
library(tidyverse)
library(wordcloud2)
library(tm)
library(quanteda)
library(RTextTools)
knitr::opts_chunk$set(echo = TRUE, warn = F, message = F)
options(stringsAsFactors = F)
setwd("~/GitHub/CUNY_MSDA/Fall_2017/DATA_607/DATA_607_Project_4")
# Training Files
ham.one.dir <- list.files("/easy_ham/", full.names = T, recursive = F)
spam.one.dir <- list.files("/spam/", full.names = T, recursive = F)
# Testing Files
ham.two.dir <- list.files("/easy_ham_2/", full.names = T, recursive = F)
spam.two.dir <- list.files("/spam_2/", full.names = T, recursive = F)
# Combine testing files
comb <- c(ham.two.dir, spam.two.dir)
# Training Files
ham.one.dir <- list.files(path="/easy_ham/", full.names = T, recursive = F)
setwd("~/GitHub/CUNY_MSDA/Fall_2017/DATA_607/DATA_607_Project_4")
# Training Files
ham.one.dir <- list.files(path="/easy_ham/", full.names = T, recursive = F)
setwd("~/GitHub/CUNY_MSDA/Fall_2017/DATA_607/DATA_607_Project_4")
# Training Files
ham.one.dir <- list.files(path = "/easy_ham/", full.names = T, recursive = F)
# Training Files
ham.one.dir <- list.files(path = "/easy_ham", full.names = T, recursive = F)
# Training Files
ham.one.dir <- list.files(path = "easy_ham/", full.names = T, recursive = F)
spam.one.dir <- list.files("spam/", full.names = T, recursive = F)
setwd("~/GitHub/CUNY_MSDA/Fall_2017/DATA_607/DATA_607_Project_4")
# Training Files
ham.one.dir <- list.files("easy_ham/", full.names = T, recursive = F)
spam.one.dir <- list.files("spam/", full.names = T, recursive = F)
# Testing Files
ham.two.dir <- list.files("easy_ham_2/", full.names = T, recursive = F)
spam.two.dir <- list.files("spam_2/", full.names = T, recursive = F)
# Combine testing files
comb <- c(ham.two.dir, spam.two.dir)
head(spam.two.dir)
head(spam.two.dir[1])
head(readLines(spam.two.dir))
head(readLines(spam.two.dir[1]))
head(readLines(ham.one.dir[1]))
tail(readLines(ham.one.dir[1]))
tail(readLines(ham.one.dir[1]), 10)
head(readLines(ham.one.dir[1]), 10)
head(readLines(ham.one.dir[1]), 15)
head(readLines(ham.one.dir[1]), 20)
head(readLines(ham.one.dir[1]), 25)
head(readLines(ham.one.dir[1]), 40)
knitr::opts_chunk$set(echo = TRUE, warn = F, message = F)
knitr::opts_chunk$set(echo = TRUE, warn = F, message = F)
knitr::opts_chunk$set(echo = TRUE, warn = F, message = F)
install.packages("knitr")
knitr::opts_chunk$set(echo = TRUE, warn = F, message = F)
options(stringsAsFactors = F)
library(tidyverse)
install.packages("tidyverse")
install.packages("wordcloud2")
install.packages("tm")
install.packages("quanteda")
install.packages("RTextTools")
knitr::opts_chunk$set(echo = TRUE, warn = F, message = F)
options(stringsAsFactors = F)
library(tidyverse)
install.packages("XML")
library(tidyverse)
library(wordcloud2)
library(tm)
library(RTextTools)
library(quanteda)
install.packages("XML")
install.packages("tidyverse")
install.packages("tidyverse")
library(tidyverse)
library(wordcloud2)
library(tm)
library(quanteda)
install.packages("quanteda")
library(tidyverse)
library(wordcloud2)
library(tm)
library(quanteda)
library(RTextTools)
for (i in length(comb)){
read_f <- readLines(comb[i])
gsub(".*\n$", "", read_f[i])
}
head(comb)
head(comb[1])
for (i in length(comb)){
read_f <- readLines(comb[i])
gsub(".*\n$", "", read_f)
}
readLines(comb[1])
for (i in length(comb)){
read_f <- readLines(comb[i])
gsub("^.*\n$", "", read_f)
}
readLines(comb[1])
for (i in length(comb)){
read_f <- readLines(comb[i])
gsub("^.*\\s+$", "", read_f)
}
readLines(comb[1])
for (i in length(comb)){
read_f <- readLines(comb[i])
gsub("^.*\\s*$", "", read_f)
}
readLines(comb[1])
for (i in length(comb)){
read_f <- readLines(comb[i])
gsub("^.*[Date:]$", "", read_f)
}
readLines(comb[1])
for (i in length(comb)){
read_f <- readLines(comb[i])
gsub("\\s*$", "", read_f)
}
readLines(comb[1])
for (i in length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub("\\s*$", "", read_f)
}
read_f <- readLines(comb[i])
readLines(comb[1])
for (i in length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub(".*$Date:", "", read_f)
}
readLines(comb[1])
for (i in length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub(".*\n$", "", read_f)
}
readLines(comb[1])
for (i in length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub(".*\n+$", "", read_f)
}
readLines(comb[1])
for (i in length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub("\n+$", "", read_f)
}
readLines(comb[1])
for (i in length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub("\\s+$", "", read_f)
}
readLines(comb[1])
knitr::opts_chunk$set(echo = TRUE, warn = F, message = F)
options(stringsAsFactors = F)
library(tidyverse)
library(wordcloud2)
library(tm)
library(quanteda)
library(RTextTools)
setwd("~/GitHub/CUNY_MSDA/Fall_2017/DATA_607/DATA_607_Project_4")
for (i in length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub(".*\\s+$", "", read_f)
}
readLines(comb[1])
for (i in 1:length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub(".*\\s+$", "", read_f)
}
readLines(comb[1])
for (i in 1:length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub("\\s+$", "", read_f)
}
readLines(comb[1])
for (i in 1:length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub("^\\s*$", "", read_f)
}
readLines(comb[1])
for (i in 1:length(comb)){
read_f <- readLines(comb[i])
read_f[i] <- gsub("^\\s*$", "", read_f[i])
}
readLines(comb[1])
for (i in 1:length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub("^\\s*$", "", read_f[i])
}
readLines(comb[1])
for (i in 1:length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub("^.*\\s*$", "", read_f[i])
}
readLines(comb[1])
for (i in 1:length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub("^.*[Date:]$", "", read_f[i])
}
readLines(comb[1])
for (i in 1:length(comb)){
read_f[i] <- readLines(comb[i])
read_f <- gsub("^.*[Date:]$", "", read_f[i])
}
for (i in 1:length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub("^.*[Date:]$", "", read_f)
}
readLines(comb[1])
for (i in 1:length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub("^[::space::]*$", "", read_f)
}
readLines(comb[1])
for (i in 1:length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub("[[:space:]*$", "", read_f)
}
for (i in 1:length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub("[[:space:]]*$", "", read_f)
}
readLines(comb[1])
for (i in 1:length(comb)){
comb <- readLines(comb[i])
comb[i] <- gsub("[[:space:]]*$", "", comb)
}
for (i in 1:length(comb)){
comb <- readLines(comb[i])
comb <- gsub("[[:space:]]*$", "", comb)
}
for (i in 1:length(comb)){
read_f <- readLines(comb[i])
comb <- gsub("[[:space:]]*$", "", read_f)
}
for (i in 1:length(comb)){
read_f <- readLines(comb[i])
read_f <- gsub("[[:space:]]*$", "", read_f)
}
knitr::opts_chunk$set(echo = TRUE, warn = F, message = F)
options(stringsAsFactors = F)
library(tidyverse)
library(wordcloud2)
library(tm)
library(quanteda)
library(RTextTools)
setwd("~/GitHub/CUNY_MSDA/Fall_2017/DATA_607/DATA_607_Project_4")
