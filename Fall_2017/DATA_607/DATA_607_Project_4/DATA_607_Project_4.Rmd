---
title: "DATA 607 - Project 4"
author: "Joshua Sturm"
date: "November 2, 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warn = F, message = F)
options(stringsAsFactors = F)
```

I downloaded the Enron spam dataset from [here](http://www2.aueb.gr/users/ion/data/enron-spam/).

## Import libraries
```{r libraries}
library(tidyverse)
library(wordcloud2)
library(tm)
library(quanteda)
library(RTextTools)
```


## Import files
```{r importfiles}

# Set working directory, import files as a corpus, and then convert each to a document matrix

setwd("~/GitHub/CUNY_MSDA/Fall_2017/DATA_607/DATA_607_Project_4")

# train.spam.corpus <- VCorpus(DirSource(directory="train/spam"))
# train.ham.corpus <- TermDocumentMatrix(VCorpus(DirSource(directory="train/ham")))
# test.spam.corpus <- TermDocumentMatrix(Corpus(DirSource(directory="test/spam")))
# test.ham.corpus <- TermDocumentMatrix(Corpus(DirSource(directory="test/ham")))


```

```{r}
# direc <- "train/ham/"
# train.ham <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
# direc <- "train/spam/"
# train.spam <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
direc <- "test/ham/"
test.ham <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
meta(test.ham, tag = "type") <- "ham"
direc <- "test/spam/"
test.spam <- VCorpus(DirSource(directory = direc), readerControl = list(language = "en"))
meta(test.spam, tag = "type") <- "spam"
```

```{r}
test.ham <- test.ham %>%
    tm_map(content_transformer(tolower)) %>%
    tm_map(stripWhitespace) %>%
    tm_map(removePunctuation) %>%
    tm_map(removeNumbers) %>%
    tm_map(removeWords, stopwords("english")) %>%
    tm_map(stemDocument)

test.spam <- test.spam %>%
    tm_map(content_transformer(tolower)) %>%
    tm_map(stripWhitespace) %>%
    tm_map(removePunctuation) %>%
    tm_map(removeNumbers) %>%
    tm_map(removeWords, stopwords("english")) %>%
    tm_map(stemDocument)
    
# train.ham <- train.ham %>%
#     tm_map(content_transformer(tolower)) %>%
#     tm_map(stripWhitespace) %>%
#     tm_map(removePunctuation) %>%
#     tm_map(removeNumbers) %>%
#     tm_map(removeWords, stopwords("english")) %>%
#     tm_map(stemDocument)
# 
# train.spam <- train.spam %>%
#     tm_map(content_transformer(tolower)) %>%
#     tm_map(stripWhitespace) %>%
#     tm_map(removePunctuation) %>%
#     tm_map(removeNumbers) %>%
#     tm_map(removeWords, stopwords("english")) %>%
#     tm_map(stemDocument)
```

```{r}
# test.ham <- tm_map(test.ham, PlainTextDocument)
# test.spam <- tm_map(test.spam, PlainTextDocument)

comb <- c(test.ham, test.spam, recursive=T)
comb <- TermDocumentMatrix(comb)
comb <- removeSparseTerms(comb, sparse = 0.95)
tr <- sample(comb)
# tr <- comb[1:4393, ]
# ts <- comb[4394:5857, ]


# test.ham <- TermDocumentMatrix(test.ham)
# test.spam <- TermDocumentMatrix(test.spam)
# 
# test.ham <- removeSparseTerms(test.ham, 0.95)
# test.spam <- removeSparseTerms(test.spam, 0.95)




```

```{r}
types <- unlist(meta(tr, "type")[,1])
container <- create_container(comb, types, trainSize = 1:248, testSize = 249:326, virgin = FALSE)



```





